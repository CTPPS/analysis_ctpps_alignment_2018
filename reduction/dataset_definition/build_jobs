#!/bin/bash

streams=(
	#"Commissioning"
	"EGamma"
	"SingleMuon"
	"ZeroBias"
)

dataset_exts=(
	"Commissioning2018-PromptReco-v1/MINIAOD"

	"Run2018A-PromptReco-v3/MINIAOD"
	"Run2018A-PromptReco-v2/MINIAOD"
	"Run2018A-PromptReco-v1/MINIAOD"

	"Run2018B-PromptReco-v2/MINIAOD"
	"Run2018B-PromptReco-v1/MINIAOD"

	"Run2018C-PromptReco-v3/MINIAOD"
	"Run2018C-PromptReco-v2/MINIAOD"
	"Run2018C-PromptReco-v1/MINIAOD"

	"Run2018D-PromptReco-v2/MINIAOD"
	"Run2018D-PromptReco-v1/MINIAOD"
)

template_file="job_template.py"
check_template_file="CheckRootFile_template"

config_file="cfg.py"
log_file="log"
job_log_file="job_log"
check_file="CheckRootFile.cc"
finished_file="finished"
success_file="success"

#----------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------

function MakeInputFiles()
{
	# TODO: currently, there is a problem in DAS which doesn't seem to account for the "run in [...]" statement
	# a workaround below

	# reset list of files
	rm -f "$dir_out/input_files"

	# get list of files
	runs=""
	for run in `cat "$dir_out/run_ls_selection.json" | grep -Po '".*?"' | sed 's/"//g'`
	do
		cache_file="input_file_cache/${stream}_${run}"
		if [ ! -f "$cache_file" ]
		then
			for ext in ${dataset_exts[*]}
			do
				#echo "    dasgoclient --query \"file dataset=/$stream/$ext run=$run\""
				dasgoclient --query "file dataset=/$stream/$ext run=$run" > "$cache_file"

				if [ -s "$cache_file" ]
				then
					break
				fi
			done
		fi

		if [ ! -s "$cache_file" ]
		then
			echo "WARNING: empty cache file $cache_file"
		fi

		cat "$cache_file" >> "$dir_out/input_files"
	done
}

#----------------------------------------------------------------------------------------------------

function MakeConfig()
{
	(
		echo "#!/bin/sh"
		echo "export HOME=\"/afs/cern.ch/exp/totem/scratch/jkaspar\""
		echo ""
		echo "source \"/cvmfs/cms.cern.ch/cmsset_default.sh\""
		echo "cd \"$CMSSW_BASE\""
		echo "cmsenv"
		echo "cd \"$execute_dir\""
		echo ""
		echo "# grid proxy configuration"
		echo "export X509_USER_PROXY=\"/afs/cern.ch/user/j/jkaspar/x509up_u2177\""
		echo ""
		cat "common_job_code"
		echo ""
		echo "("
		echo ""
		echo "date"
		echo ""
		echo "voms-proxy-info"
		echo ""
		echo "# prepare directory for reco"
		echo "mkdir -p \"$reco_dir\""
		echo ""
		echo "# run CMSSW"
		echo "cmsRun \"$config_file\" > \"$log_file\""
		echo "cmsRun_retCode=\$?"
		echo "if [ \$cmsRun_retCode -ne 0 ]"
		echo "then"
		echo "    echo \"cmsRun crashed: return code = \$cmsRun_retCode\""
		echo "    ls -l > \"$finished_file\""
		echo "    exit 1"
		echo "fi"
		echo ""
		echo "date"
		echo ""
		echo "# check ROOT file consistency"
		echo "root -b -q -l \"$check_file\" 2> /dev/null"
		echo "if [ \$? -eq 0 ]"
		echo "then"
		echo "    # workaround for problems with eos cp"
		echo "    export LD_LIBRARY_PATH=\"\""
		echo "    "
		echo "    success=1"
		echo "    outputDir=\"$storage_dir\""
		echo "    RemoteMkdir \"\$outputDir\""
    	echo "    SafeCmd RemoteCopy \"$config_file\" \"\$outputDir/${output_tag}_cfg.py\" || success=0"
    	echo "    SafeCmd RemoteCopy \"$log_file\" \"\$outputDir/${output_tag}.log\" || success=0"
    	echo "    SafeCmd RemoteCopy \"run_ls_selection.json\" \"\$outputDir/${output_tag}.json\" || success=0"
    	echo "    SafeCmd RemoteCopy \"$output_file\" \"\$outputDir/${output_tag}.root\" || success=0"
		echo "    if [ \$success -eq 1 ]"
		echo "    then"
		echo "        touch \"$success_file\""
		echo "    fi"
		echo "else"
		echo "    echo \"The reco file is corrupted, you will need to rerun this job.\""
		echo "fi"
		echo ""
		echo "ls -l > \"$finished_file\""
		echo ""
		echo ") &> $job_log_file"
	) > "$dir_out/job"

	chmod u+x "$dir_out/job"
}

#----------------------------------------------------------------------------------------------------

function MakeScript()
{
	cat "$template_file" | sed -e "\
			s|\$input_file_commands|$input_file_commands|;\
			s|\$output_file|$output_file|;\
		" > "$dir_out/$config_file"
}

#----------------------------------------------------------------------------------------------------

function MakeCheckScript()
{
    cat "$check_template_file" | sed "\
        s|\$file|$output_file|;\
      " > "$dir_out/$check_file"
}

#----------------------------------------------------------------------------------------------------

function ProcessOne()
{
	# make output directory
	dir_out="../work_dir/fill$fill/xangle${xangle}_beta${beta}/$stream"
	mkdir -p "$dir_out"

	# set directories, filenames, etc.
	execute_dir="`pwd -P`/$dir_out"
	reco_dir="/pool"

	storage_dir="/eos/totem/data/ctpps/reconstruction/2018/physics_runs/version2"

	output_file="$reco_dir/fill${fill}_xangle${xangle}_beta${beta}_$stream.root"
	output_tag="fill${fill}_xangle${xangle}_beta${beta}_$stream"

   	# copy JSON selection
   	cp "$f_in" "$dir_out/run_ls_selection.json"
   
	# get input-file list
	#if [ ! -f "$dir_out/input_files" ]
	#if [ ! -f "$dir_out/input_files" -o ! -s "$dir_out/input_files" ]
	#then
		MakeInputFiles
	#fi

	if [ ! -s "$dir_out/input_files" ]
	then
		echo "ERROR: input_files empty in $dir_out"
	fi

	# process input files
	(
		echo "def AddFiles(source):"
		for file in `cat "$dir_out/input_files"|sort|uniq`
		do
			echo "  source.fileNames.append(\"$file\")"
		done
	) > "$dir_out/input_files.py"

	# make config
	MakeConfig

	# make job script
	MakeScript

	# make check script
	MakeCheckScript
}

#----------------------------------------------------------------------------------------------------

mkdir -p "input_file_cache"

for f_in in json_selected/*
do
	size=$(wc -c <"$f_in")

	if [ "$size" -le 3 ]
	then
		continue
	fi

	tag=${f_in#*/}
	tag=${tag%.*}

	tag=${tag#fill_}
	fill=${tag%%_*}

	tag=${tag#*_xangle_}
	xangle=${tag%%_*}

	tag=${tag#*_betast_}
	beta=${tag%%_*}

	echo "$f_in"

	for stream in ${streams[*]}
	do
		ProcessOne &
	done

	wait
done
